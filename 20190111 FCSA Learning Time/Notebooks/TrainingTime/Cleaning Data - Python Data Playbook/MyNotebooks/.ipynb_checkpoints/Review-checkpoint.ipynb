{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review for Section of Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "td {text-align:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "td {text-align:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Understanding Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Python Code|Notes/Explanation|\n",
    "| :---      | :---            |\n",
    "|__df.dtypes__|View the data types of columns|\n",
    "|__df['year'].astype(float)__|Convert column to a new type|\n",
    "|__df['year] = df['year'].astype(float)__|Assign converted type back to dataframe|\n",
    "|__pd.to_numeric(df.height, errors=\"coerce\")__|Coerse conversion errors - conversion errors are set to 'nan' |\n",
    "|__df['year'].min()__|Call aggregation function on series|\n",
    "|__df.agg(['min','max','mean','std'])__|Use .agg to call multiple functions on dataframe|\n",
    "|__df['height'].transform(lambda x: x / 10)__|Transform a column of data using custom function|\n",
    "|__df.groupby('artist').transform('nunique')__|Transform a column using built-in function|\n",
    "|__df.filter(items=['id','artist'])__|View only certain columns|\n",
    "|__df.filter(regex=\"(?i)year\")__|View columns that match a regex, defaults to case sensitive ((?i) indicates case insensitive)|\n",
    "|__df.filter(axis=0, like='100', case=False)__|Switch the axis to filter rows based on index (not on column content)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Drop and Rename columns in DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Python Code|Notes/Explanation|\n",
    "| :---      | :---            |\n",
    "|__df.drop('id',axis=1)__|Drop a single column|\n",
    "|__df.drop(columns=['height','width'])__|Drop multiple columns|\n",
    "|__df.drop('id',axis=1,inplace=True)__|Drop a column inplace (default is inplace=False, which returns new dataframe)|\n",
    "|__df=pd.read_csv('file.csv', usecols=['artist','title'])__|Only import certain columns (by name)|\n",
    "|__df.columns.str.lower()__|Generate a list of new column names using str function lower|\n",
    "|__[x.uppper() for x in df.columns]__|Generate a list of new column names using a list comprehension|\n",
    "|__map(lambda x: x.lower(), df.columns)__|Use map to permanently change the column names|\n",
    "|__df.rename(columns={'start':'finish'})__|Rename a column, returns new dataframe (original df is unchanged)|\n",
    "|__df.rename(columns=lambda x: x.uppper(), inplace=True)__|Use rename with lambda and inplace to alter existing df|\n",
    "|__df=pd.read_csv('file.csv',names[col_one','col_two'],header=0)__|Rename columns as df read in, replace existing header row|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 Indexing and Filtering Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Python Code|Notes/Explanation|\n",
    "| :---      | :---            |\n",
    "|__df['col_name']__|Access a column as a pandas series|\n",
    "|__df['col_name'][1]__|Acces a single row on a column|\n",
    "|__df[1:5]__|Access a range of rows with a slice (slice is inclusive/exclusive), returns rows in integer positions 1,2,3,4|\n",
    "|__df[df['year'] > 1800]__|Use a basic filter|\n",
    "|__df.loc[ROWS,COLUMNS]__|Basic format of dataframe .loc function|\n",
    "|__df.loc[0:2,:]__|Access a slice of row using index labels and all column, loc slice is inclusive/inclusive|\n",
    "|__df.loc[0:2,['col_name1','col_name2]]__|Can use lists for row labels or column names for specific rows/columns|\n",
    "|__df.loc[df['artist'] == 'Artist Name',:]__|Filter rows using boolean series (combine criteria with & (and), \\| (or) and ~ not))|\n",
    "|__df.iloc[ROWS,COLS]__|Like .loc, except uses integer positioning instead of row labels and column names|\n",
    "|__df.iloc[0:2,:]__|slice uses integer position and is inclusive/exclusive, so returns rows at integer postion 0,1 (not 2)|\n",
    "|__df.iloc[[1,5],[12,100]]__|Like .loc, can use lists to define rows and columns|\n",
    "|__df['col_name'].str.contains('search')__|Generate pandas series of boolean based on search|\n",
    "|__df.loc[df['col_name'].str.contains('search')]__|Filter dataframe using str.contains|\n",
    "|__df.loc[df['col_name'].str.contains('search1\\|search2',case=False,regex=True)]__|Filtering using case insensitive and regular expression|\n",
    "|__df.loc[df['col_name'].astype(str).contains('search',na=False)]__|Convert to string and ignore any 'nan' rows|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 Handling Bad, Missing and Duplicate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Python Code|Notes/Explanation|\n",
    "| :---      | :---            |\n",
    "|__df['title'].str.strip()__|Strip whitespace from entire column|\n",
    "|__df['title'].transform(lambda x: x.strip())__|Strip whitespace using lambda for greater flexibility|\n",
    "|__df.replace({'col_name':{'value':nan})__|Import nan from numpy and replace all specific values with nan|\n",
    "|__implace=True__|In many situations, use inplace=True to change original data (modify source)|\n",
    "|__df.loc[df['col_name']=='value', ['col_name']]=nan__|Replace specific values in a column with NaN|\n",
    "|__df.fillna(-1)__|Fill all NaN values in entire dataframe with -1|\n",
    "|__df.fillna(value={'col':0})__|Fill NaN values in a specific column|\n",
    "|__df.dropna()__|Drop rows with ANY NaN values, equivalent to df.dropna(how='any')|\n",
    "|__df.dropna(how='all')__|Drop rows with ALL NaN values|\n",
    "|__df.dropna(thresh=15)__|Drop rows with at least 15 NaN values|\n",
    "|__df.dropna(subset=['col_1','col_2'],inplace=True)__|Drop rows based on NaN values in specific set of columns|\n",
    "|__df.drop_duplicates()__|Drop all duplicates|\n",
    "|__df.drop_duplicates(subset=['col_1','col_2'])__|Drop duplicates if they match against a subset of columns|\n",
    "|__df.drop_duplicates(keep=False)__|Specify which rows to keep: 'first', 'last' or False (don't keep any duplicates)|\n",
    "|__df.loc[df.duplicated(subset=['col1','col2'],keep=False)]__|Find and see duplicates using .loc across specific columns|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
