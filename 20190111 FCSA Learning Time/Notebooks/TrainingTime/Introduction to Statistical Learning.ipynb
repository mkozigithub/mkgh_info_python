{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Introductin to Statisctical Learning (7th ed.)\n",
    "Url: http://www-bcf.usc.edu/~gareth/ISL/  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this will left align the markdown tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book Notation Conventions\n",
    "|notation|example|explaination|\n",
    "| --- | --- | --- |\n",
    "| $n$ | &nbsp; | number of observations |\n",
    "| $p$ | &nbsp; | number of variables available for prediction |\n",
    "| $x_{i,j}$ | &nbsp; | $j^{th}$ variable for the $i^{th}$ observationp, where $i$ = 1,2,..,$n$ and $j$ = 1,2,...,$p$ |\n",
    "| $X$ | &nbsp; | $n$ x $p$ matrix whose $(i,j)$th element is $x_{i,j}$ |\n",
    "| &nbsp; | &nbsp; | $X = \\begin{pmatrix}x_{1,1} & x_{1,2} & ... & x_{1,p}\\\\. & . & ... & .\\\\x_{n,1} & x_{n,2} & ... & x_{n,p}\\end{pmatrix}$ |\n",
    "| rows of $X$ | &nbsp; | $X = x_1, x_2, ..., x_n$ |\n",
    "| $x_i$ | &nbsp; | row of $X$: $x_i = \\begin{pmatrix}x_{i,1} \\\\ x_{i,2} \\\\ .. \\\\ .. \\\\ x_{i,p}\\end{pmatrix}$ |\n",
    "| columns of $X$ | &nbsp; | $X = \\bf{x_1}, \\pmb{x_2}, ..., \\bf{x_n}$ |\n",
    "| $\\pmb{x_j}$ | &nbsp; | column of $X$: $\\bf{x_j} = \\begin{pmatrix}x_{1,j} \\\\ x_{2,j} \\\\ .. \\\\ .. \\\\ x_{n,j}\\end{pmatrix}$ |\n",
    "| $X$ | &nbsp; | $X = (\\bf{x_1}, \\bf{x_2}, ..., \\bf{x_n}) = \\begin{pmatrix}x_1^T \\\\ x_2^T \\\\ .. \\\\ .. \\\\ x_n^T \\end{pmatrix}$ |\n",
    "| &nbsp; | &nbsp; | $x_i^T = (x_{i,1} \\; x_{i,2} \\; ... \\; x_{i,p})$ |\n",
    "| $\\bf{y}$ | &nbsp; | prediction values: $\\bf{y} = \\begin{pmatrix}y_1 \\\\ y_2 \\\\ .. \\\\ y_n\\end{pmatrix}$ |\n",
    "| $\\bf{a}$ | &nbsp; | vector of length $n$: $\\bf{a} = \\begin{pmatrix}a_1 \\\\ a_2 \\\\ .. \\\\ a_n\\end{pmatrix}$ |\n",
    "| $a$ | &nbsp; | vector of length  not equal to $n$: $a = \\begin{pmatrix}a_1 \\\\ a_2 \\\\ .. \\\\ a_m\\end{pmatrix}$ |\n",
    "| $\\bf{A}$ | &nbsp; | matrices denoted in bold capital |\n",
    "| $A$ | &nbsp; | random variable in noraml capital |\n",
    "| $a \\in \\mathbb{R}$ | &nbsp; | a scalar value |\n",
    "| $a \\in \\mathbb{R}^k$ | &nbsp; | a vector of length $k$ |\n",
    "| $a \\in \\mathbb{R}^{r \\times s}$ | &nbsp; | a matrix with $r$ rows and $s$ columns |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error (MSE)\n",
    "$$MSE = \\frac{1}{n} \\sum_{i=1}^n(y_i - \\hat{f}(x_i))^2$$\n",
    "where $\\hat{f}(x_i)$ is the prediction for the $i^{th}$ observation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(x_0, y_0)$ : previously unseen test observation not used to train the statistical learning method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to minimize: Ave$(y_0 - \\hat{f}(x_0))^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance Trade-Off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E(y_0 - \\hat{f}(x_0))^2 = Var(\\hat{f}(x_0)) + [Bias(\\hat{f}(x_0))]^2 + Var(\\epsilon) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasification Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Error Rate:\n",
    "$$ \\frac{1}{n}\\sum_{i=1}^nI(y_i \\not= \\hat{y}_i), \\quad where I(y_i \\not= \\hat{y}_i) = \\begin{cases}1 & y_i \\not= \\hat{y}_i \\\\ 0 &  y_i = \\hat{y}_i\\end{cases} $$\n",
    "\n",
    "Test Error Rate:\n",
    "$$ Ave(I(y_0 \\not= \\hat{y}_0)), \\quad \\text{where test set observations} = (x_0,y_0) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{Pr}(Y = j|X = x_0) $$\n",
    "_conditional probability_: the probability that $Y=j$, given observed predictor vector $x_0$  \n",
    "\n",
    "for two-class problem (class 1: $c_1$ or class 2: $c_2$):\n",
    "$$ \\begin{cases}c_1 & \\text{Pr}(Y = 1|X = x_0)>0.5 \\\\ c_2 & else\\end{cases} $$\n",
    "\n",
    "Bayes Error Rate:\n",
    "$$ 1 - E(\\text{max}_j \\text{Pr}(Y = 1|X)) $$\n",
    "where E() defines an _expected test MSE_, which is the average calculated value obtained from repeated calculations of the expression over a large number of training sets each at $x_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{Pr}(Y = j|X = x_0) = \\frac{1}{K}\\sum_{i\\in{N_0}}I(y_i = j) $$\n",
    "where $N_0$ is the set of $K$ points closest to $x_0$  \n",
    "Calculate for all cases ($j$), then pick the one with the highest probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume there is an approximate linear relationship between a single predictor variable $X$ and the quantitative response $Y$:\n",
    "\n",
    "$$ Y \\approx \\beta_0 + \\beta_1X, \\quad \\text{ where } \\beta_0 \\text{ is intercept and } \\beta_1 \\text{ is slope} $$\n",
    "\n",
    "Can use this as prediction:\n",
    "\n",
    "$$ \\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1} \\times x $$\n",
    "\n",
    "residual sum of squares (RSS):\n",
    "\n",
    "$$ RSS = (y_1 -(\\hat{\\beta_0} + \\hat{\\beta_1}x_1))^2 + (y_2 -(\\hat{\\beta_0} + \\hat{\\beta_1}x_2))^2 + \\ldots + (y_n -(\\hat{\\beta_0} + \\hat{\\beta_1}x_n))^2 $$\n",
    "\n",
    "via some calculus RSS minimizers can be calculated:\n",
    "\n",
    "$$ \\hat{\\beta_1} = \\frac{\\sum_{i=1}^n(x_i - \\overline{x})(y_i - \\overline{y})}{\\sum_{i=1}^n(x_1 - \\overline{y})} ,$$\n",
    "\n",
    "$$ \\hat{\\beta_0} = \\overline{y} - \\hat{\\beta_1}\\overline{x} ,$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;where $ \\overline{y} \\equiv \\frac{1}{n} \\sum_{i=1}^n y_i $ and $ \\overline{x} \\equiv \\frac{1}{n} \\sum_{i=1}^n x_i $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the accuracy of the coefficient estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Y = f(X) + \\epsilon = \\beta_0 + \\beta_1X + \\epsilon, $$\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;where $\\epsilon$ is a mean-zero random error term, which is a catch-all for what we miss using a simple linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard error of $\\hat{\\mu}$:\n",
    "$$ \\text{Var}(\\hat{\\mu}) = \\text{SE}(\\hat{\\mu})^2 = \\frac{\\sigma^2}{n}, \\text{ where $\\sigma$ is the standard deviation of each realization $y_i$ of $Y$}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard errors for coefficients:\n",
    "$$ SE(\\hat{\\beta_0})^2 = \\sigma^2\\left[\\frac{1}{n} + \\frac{\\overline{x}^2}{\\sum_{i=1}^n(x_i - \\overline{x})^2}\\right], SE(\\hat{\\beta_1})^2 = \\frac{\\sigma^2}{\\sum_{i=1}^n(x_i - \\hat{x})^2}, \\text{ where $\\sigma^2$} = Var(\\epsilon) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95% confidence intervals for $\\beta_0$ and $\\beta_1$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\hat{\\beta_0} \\pm 2 \\cdot \\text{SE}(\\hat{\\beta_0}), \\qquad \\hat{\\beta_1} \\pm 2 \\cdot \\text{SE}(\\hat{\\beta_1}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of Y given X\n",
    "\n",
    "$$ p(X) = \\text{Pr}(Y = k|X = x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Function ([wikipedia](https://en.wikipedia.org/wiki/Logistic_function))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A special case of the [sigmoid curve](https://en.wikipedia.org/wiki/Sigmoid_function), with equation:\n",
    "\n",
    "$$ f(x) = \\frac{L}{1 + e^{-k(x-x_0)}} $$\n",
    "where,\n",
    "* e = the natural logarithm base\n",
    "* $x_0$ = the x-value of the sigmoid's midpoint\n",
    "* $L$ = the curve's maximum value\n",
    "* k = the logistic rate or steepness of the curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Logistic Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special case of the Logistic Function with k = 1, $x_0$ = 0 and $L$ = 1, which results in:\n",
    "\n",
    "$$ f(x) = \\frac{1}{1 + e^{-x}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plugging in our standard linear regression function:  \n",
    "linear model: $y = \\beta_0 + \\beta_1X$  \n",
    "logistic model:\n",
    "$$ p = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1X)}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
